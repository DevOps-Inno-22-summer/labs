# Lab 13 
## Screenshots

1. Result of `helm install --dry-run --debug python-app python-app` command

![Part1](../images/lab13_dry_run_1.png)

![Part2](../images/lab13_dry_run_2.png)

![Part3](../images/lab13_dry_run_3.png)

![Part4](../images/lab13_dry_run_4.png)

2. Result of `kubectl get po,sts,svc,pvc` command

![Get](../images/lab13_kubectl_get.png)

3. Results of `kubectl exec pod/python-app-n -- cat data/visits.txt` commands 

* Pod `pod/python-app-0`

![Pod0](../images/lab13_visits_container_0.png)

* Pod `pod/python-app-1`

![Pod1](../images/lab13_visits_container_1.png)

* Pod `pod/python-app-2`

![Pod2](../images/lab13_visits_container_2.png)

## Questions

1. Why are `-- cat data/visits.txt` outputs different for replicas?

That is because each of the replicas has its own `visits.txt` file. Every time any page is opened, a certain replica is chosen to handle the request. That's why the results are unique - each individual request is only handled (and logged) by one replica

2. Why is ordering guarantee unnecessary?

In this particular case different replicas are responsible for the same function, do not depend on each other and do not communicate in any way. Technically, even if all except for one replicas were down, service would still fully function (as all request would simply be handled by the remaining replica)

3. How to implement parallel launch/termination of pods?

By specifying `podManagementPolicy: "Parallel"` inside of `spec:` block of `statefulset.yaml`